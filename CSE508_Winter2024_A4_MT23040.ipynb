{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "riA1tmLBhhhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0a0d79-4eff-48a6-e9f5-06effd56ff8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece -q\n",
        "!pip install transformers -q\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "zVioK8lHhkQj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW\n",
        "from torch.optim import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from rouge import Rouge\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KhtadrfWh2vE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d287310d-cc1c-4969-852b-2419fad579f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTORCH_NO_CUDA_MEMORY_CACHING=1\n",
        "!cat /proc/sys/vm/overcommit_memory\n",
        "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O6YZd7xG45l",
        "outputId": "edd08fd0-4eee-42b1-d1ed-7605bdb32c93"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTORCH_NO_CUDA_MEMORY_CACHING=1\n",
            "1\n",
            "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z0N4z6-HJI-",
        "outputId": "0170169d-70d5-4a5e-f869-2001f47438ef"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews=pd.read_csv('/content/drive/MyDrive/Reviews.csv')"
      ],
      "metadata": {
        "id": "SZk1C24XHN9N"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reviews.isna().sum())\n",
        "reviews.dropna(inplace=True)\n",
        "reviews['training'] = reviews['Text'].str.lower()  + 'TL;DR' + reviews['Summary'].str.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfv4pggeHPgD",
        "outputId": "829729af-88d7-464f-d4b4-1ea0ec64f02b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Id                         0\n",
            "ProductId                  0\n",
            "UserId                     0\n",
            "ProfileName               26\n",
            "HelpfulnessNumerator       0\n",
            "HelpfulnessDenominator     0\n",
            "Score                      0\n",
            "Time                       0\n",
            "Summary                   27\n",
            "Text                       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o4yRfCMaHo73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = reviews[['Summary','Text','training']][:5000]"
      ],
      "metadata": {
        "id": "-Td0SQGLHTR5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['training'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "BjbKy5tdBukz",
        "outputId": "72d434d8-f0c2-4184-d91a-7ef67fe575ae"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i have bought several of the vitality canned dog food products and have found them all to be of good quality. the product looks more like a stew than a processed meat and it smells better. my labrador is finicky and she appreciates this product better than  most.TL;DRgood quality dog food'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['model_input'] = reviews['Text'] + \" TL;DR \" + reviews['Summary']\n"
      ],
      "metadata": {
        "id": "09G2FvGnHV8B"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['model_input'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "xh5fcmUxB2gm",
        "outputId": "8356f443-ef66-4710-8d13-535573f7a711"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most. TL;DR Good Quality Dog Food'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_length = sum([len(review.split()) for review in reviews.model_input.values])/len(reviews)\n",
        "avg_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LFZBV-qHbMh",
        "outputId": "a3d3d7a0-f8c4-4afa-ac1c-8599c06c0582"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.1608"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 100"
      ],
      "metadata": {
        "id": "yr1pPROuHznJ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = reviews['model_input'].values.tolist()"
      ],
      "metadata": {
        "id": "ggp7Uh7qIKs8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X57iORAZCJ6n",
        "outputId": "6f33ad91-4403-4ec0-9db9-431474b60d0e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "6P08lxUQIMp3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\" TL;DR \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWMHp5qbIOSt",
        "outputId": "db052d1b-b299-4a64-fc57-7077d3eb9dbc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[24811, 26, 7707, 220]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extra_length = len(tokenizer.encode(\" TL;DR \"))"
      ],
      "metadata": {
        "id": "b7uPje2BIUfO"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_reviews, test_reviews = train_test_split(reviews, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "pP4BS5r4IYdh"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, tokenizer, reviews, max_len):\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "        self.eos = self.tokenizer.eos_token\n",
        "        self.eos_id = self.tokenizer.eos_token_id\n",
        "        self.reviews = reviews\n",
        "        self.result = []\n",
        "\n",
        "        for review in self.reviews:\n",
        "            tokenized = self.tokenizer.encode(review + self.eos)\n",
        "\n",
        "            padded = self.pad_truncate(tokenized)\n",
        "\n",
        "            self.result.append(torch.tensor(padded))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.result)\n",
        "\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.result[item]\n",
        "\n",
        "    def pad_truncate(self, name):\n",
        "        name_length = len(name) - extra_length\n",
        "        if name_length < self.max_len:\n",
        "            difference = self.max_len - name_length\n",
        "            result = name + [self.eos_id] * difference\n",
        "        elif name_length > self.max_len:\n",
        "            result = name[:self.max_len + 3]+[self.eos_id]\n",
        "        else:\n",
        "            result = name\n",
        "        return result\n"
      ],
      "metadata": {
        "id": "hhRWwwh_Ib2r"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_and_evaluate_grid_search(model, tokenizer, train_data, learning_rate, batch_size, epochs):\n",
        "    train_reviews, val_reviews = train_test_split(train_data, test_size=0.2, random_state=42)\n",
        "    train_dataset = ReviewDataset(tokenizer, train_reviews, max_length)\n",
        "    val_dataset = ReviewDataset(tokenizer, val_reviews, max_length)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for step, batch in enumerate(train_loader):\n",
        "            batch = batch.to(device)\n",
        "            outputs = model(input_ids=batch, labels=batch)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                outputs = model(input_ids=batch, labels=batch)\n",
        "                loss = outputs.loss\n",
        "                total_val_loss += loss.item()\n",
        "\n",
        "        average_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {average_val_loss}\")\n",
        "\n",
        "    return average_val_loss\n"
      ],
      "metadata": {
        "id": "V03c1cggIozS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [3e-4, 1e-4]\n",
        "batch_sizes = [16, 32]\n",
        "num_epochs = [5, 10]\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_hyperparams = {}\n",
        "best_model = None\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for bs in batch_sizes:\n",
        "        for epochs in num_epochs:\n",
        "            average_val_loss = train_and_evaluate_grid_search(model, tokenizer, train_reviews, lr, bs, epochs)\n",
        "            print(f\"Validation Loss for LR={lr}, BS={bs}, Epochs={epochs}: {average_val_loss}\")\n",
        "            if average_val_loss < best_loss:\n",
        "                best_loss = average_val_loss\n",
        "                best_hyperparams = {'learning_rate': lr, 'batch_size': bs, 'num_epochs': epochs}\n",
        "                best_model = model.state_dict()\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_hyperparams)\n",
        "\n",
        "with open('best_model_new.pkl', 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "print(\"Best model saved to best_model_new.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxbgOWVWKeTH",
        "outputId": "a198b869-1b25-4b2c-9b50-e13b80cc7470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Validation Loss: 2.7017658416261066\n",
            "Epoch 2/5, Validation Loss: 2.6513028347745853\n",
            "Epoch 3/5, Validation Loss: 2.622822213680186\n",
            "Epoch 4/5, Validation Loss: 2.6022404559115144\n",
            "Epoch 5/5, Validation Loss: 2.58846164764242\n",
            "Validation Loss for LR=0.0003, BS=16, Epochs=5: 2.58846164764242\n",
            "Epoch 1/10, Validation Loss: 2.5864162647977786\n",
            "Epoch 2/10, Validation Loss: 2.5714586998553988\n",
            "Epoch 3/10, Validation Loss: 2.562268911524022\n",
            "Epoch 4/10, Validation Loss: 2.5549485429804375\n",
            "Epoch 5/10, Validation Loss: 2.548440360008402\n",
            "Epoch 6/10, Validation Loss: 2.542212151466532\n",
            "Epoch 7/10, Validation Loss: 2.537845474608401\n",
            "Epoch 8/10, Validation Loss: 2.533649053979427\n",
            "Epoch 9/10, Validation Loss: 2.5297666052554515\n",
            "Epoch 10/10, Validation Loss: 2.5256807804107666\n",
            "Validation Loss for LR=0.0003, BS=16, Epochs=10: 2.5256807804107666\n",
            "Epoch 1/5, Validation Loss: 2.5203411678473153\n",
            "Epoch 2/5, Validation Loss: 2.515917291243871\n",
            "Epoch 3/5, Validation Loss: 2.5133501092592874\n",
            "Epoch 4/5, Validation Loss: 2.5114616056283317\n",
            "Epoch 5/5, Validation Loss: 2.510048588116964\n",
            "Validation Loss for LR=0.0003, BS=32, Epochs=5: 2.510048588116964\n",
            "Epoch 1/10, Validation Loss: 2.5143671929836273\n",
            "Epoch 2/10, Validation Loss: 2.5091858307520547\n",
            "Epoch 3/10, Validation Loss: 2.5075473388036094\n",
            "Epoch 4/10, Validation Loss: 2.505711297194163\n",
            "Epoch 5/10, Validation Loss: 2.504875381787618\n",
            "Epoch 6/10, Validation Loss: 2.5032448172569275\n",
            "Epoch 7/10, Validation Loss: 2.5015422701835632\n",
            "Epoch 8/10, Validation Loss: 2.5004317462444305\n",
            "Epoch 9/10, Validation Loss: 2.4994735419750214\n",
            "Epoch 10/10, Validation Loss: 2.4984469215075173\n",
            "Validation Loss for LR=0.0003, BS=32, Epochs=10: 2.4984469215075173\n",
            "Epoch 1/5, Validation Loss: 2.5104013453138636\n",
            "Epoch 2/5, Validation Loss: 2.507238631552838\n",
            "Epoch 3/5, Validation Loss: 2.506374181585109\n",
            "Epoch 4/5, Validation Loss: 2.5056001429862165\n",
            "Epoch 5/5, Validation Loss: 2.5047365350926176\n",
            "Validation Loss for LR=0.0001, BS=16, Epochs=5: 2.5047365350926176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_file = 'best_model_new.pkl'\n",
        "if os.path.exists(best_model_file):\n",
        "    with open(best_model_file, 'rb') as f:\n",
        "        best_model_state_dict = pickle.load(f)\n",
        "else:\n",
        "    raise FileNotFoundError(\"Best model file not found. Please train a model first.\")\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "model.load_state_dict(best_model_state_dict)\n",
        "\n",
        "\n",
        "new_learning_rate = 1e-3\n",
        "new_batch_size = 64\n",
        "new_num_epochs = 10\n",
        "\n",
        "\n",
        "optimizer = SGD(model.parameters(), lr=new_learning_rate)\n",
        "\n",
        "train_and_evaluate_grid_search(model, tokenizer, train_reviews, new_learning_rate, new_batch_size, new_num_epochs)\n",
        "\n",
        "with open(best_model_file, 'wb') as f:\n",
        "    pickle.dump(model.state_dict(), f)\n",
        "\n",
        "print(\"Training resumed and updated best model saved.\")\n"
      ],
      "metadata": {
        "id": "pddBkou1b6-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def topk(probs, n=15):\n",
        "    probs = torch.softmax(probs, dim= -1)\n",
        "    tokensProb, topIx = torch.topk(probs, k=n)\n",
        "    tokensProb = tokensProb / torch.sum(tokensProb)\n",
        "    tokensProb = tokensProb.cpu().detach().numpy()\n",
        "    choice = np.random.choice(n, 1, p = tokensProb)\n",
        "    tokenId = topIx[choice][0]\n",
        "    return int(tokenId)"
      ],
      "metadata": {
        "id": "tHK9BcbCKyTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_infer(model, tokenizer, review, max_length=15):\n",
        "    review_encoded = tokenizer.encode(review)\n",
        "    result = review_encoded\n",
        "    initial_input = torch.tensor(review_encoded).unsqueeze(0).to(device)\n",
        "    with torch.set_grad_enabled(False):\n",
        "        output = model(initial_input)\n",
        "        logits = output.logits[0,-1]\n",
        "        result.append(topk(logits))\n",
        "        for _ in range(max_length):\n",
        "            input = torch.tensor(result).unsqueeze(0).to(device)\n",
        "            output = model(input)\n",
        "            logits = output.logits[0,-1]\n",
        "            res_id = topk(logits)\n",
        "            if res_id == tokenizer.eos_token_id:\n",
        "                return tokenizer.decode(result)\n",
        "            else:\n",
        "                result.append(res_id)\n",
        "\n",
        "    return tokenizer.decode(result)"
      ],
      "metadata": {
        "id": "OYIdQTg0K6XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_model.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2XzO-MHXuVD",
        "outputId": "d9d7fdc1-6b9c-49b5-f1c1-ebce652ea11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['transformer.wte.weight', 'transformer.wpe.weight', 'transformer.h.0.ln_1.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.0.attn.c_attn.weight', 'transformer.h.0.attn.c_attn.bias', 'transformer.h.0.attn.c_proj.weight', 'transformer.h.0.attn.c_proj.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.1.ln_1.bias', 'transformer.h.1.attn.c_attn.weight', 'transformer.h.1.attn.c_attn.bias', 'transformer.h.1.attn.c_proj.weight', 'transformer.h.1.attn.c_proj.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.2.ln_1.weight', 'transformer.h.2.ln_1.bias', 'transformer.h.2.attn.c_attn.weight', 'transformer.h.2.attn.c_attn.bias', 'transformer.h.2.attn.c_proj.weight', 'transformer.h.2.attn.c_proj.bias', 'transformer.h.2.ln_2.weight', 'transformer.h.2.ln_2.bias', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.3.ln_1.bias', 'transformer.h.3.attn.c_attn.weight', 'transformer.h.3.attn.c_attn.bias', 'transformer.h.3.attn.c_proj.weight', 'transformer.h.3.attn.c_proj.bias', 'transformer.h.3.ln_2.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.4.ln_1.weight', 'transformer.h.4.ln_1.bias', 'transformer.h.4.attn.c_attn.weight', 'transformer.h.4.attn.c_attn.bias', 'transformer.h.4.attn.c_proj.weight', 'transformer.h.4.attn.c_proj.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.4.ln_2.bias', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.5.ln_1.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.5.attn.c_attn.weight', 'transformer.h.5.attn.c_attn.bias', 'transformer.h.5.attn.c_proj.weight', 'transformer.h.5.attn.c_proj.bias', 'transformer.h.5.ln_2.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.6.ln_1.weight', 'transformer.h.6.ln_1.bias', 'transformer.h.6.attn.c_attn.weight', 'transformer.h.6.attn.c_attn.bias', 'transformer.h.6.attn.c_proj.weight', 'transformer.h.6.attn.c_proj.bias', 'transformer.h.6.ln_2.weight', 'transformer.h.6.ln_2.bias', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.7.ln_1.weight', 'transformer.h.7.ln_1.bias', 'transformer.h.7.attn.c_attn.weight', 'transformer.h.7.attn.c_attn.bias', 'transformer.h.7.attn.c_proj.weight', 'transformer.h.7.attn.c_proj.bias', 'transformer.h.7.ln_2.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.8.ln_1.weight', 'transformer.h.8.ln_1.bias', 'transformer.h.8.attn.c_attn.weight', 'transformer.h.8.attn.c_attn.bias', 'transformer.h.8.attn.c_proj.weight', 'transformer.h.8.attn.c_proj.bias', 'transformer.h.8.ln_2.weight', 'transformer.h.8.ln_2.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.9.ln_1.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.9.attn.c_attn.weight', 'transformer.h.9.attn.c_attn.bias', 'transformer.h.9.attn.c_proj.weight', 'transformer.h.9.attn.c_proj.bias', 'transformer.h.9.ln_2.weight', 'transformer.h.9.ln_2.bias', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.10.ln_1.weight', 'transformer.h.10.ln_1.bias', 'transformer.h.10.attn.c_attn.weight', 'transformer.h.10.attn.c_attn.bias', 'transformer.h.10.attn.c_proj.weight', 'transformer.h.10.attn.c_proj.bias', 'transformer.h.10.ln_2.weight', 'transformer.h.10.ln_2.bias', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.11.ln_1.weight', 'transformer.h.11.ln_1.bias', 'transformer.h.11.attn.c_attn.weight', 'transformer.h.11.attn.c_attn.bias', 'transformer.h.11.attn.c_proj.weight', 'transformer.h.11.attn.c_proj.bias', 'transformer.h.11.ln_2.weight', 'transformer.h.11.ln_2.bias', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.11.mlp.c_proj.bias', 'transformer.ln_f.weight', 'transformer.ln_f.bias', 'lm_head.weight'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/best_model.pkl', 'rb') as f:\n",
        "    best_model = pickle.load(f)"
      ],
      "metadata": {
        "id": "yCx1bgysUzbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(best_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4-ZotvNVJaq",
        "outputId": "958b6e10-ae65-418c-e118-649e5b2beb31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "model.to(device)\n",
        "model.load_state_dict(best_model)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "hATQKESvY9JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for review in test_reviews:\n",
        "    print(\"Original Review: \", review)\n",
        "    summary = model_infer(model, tokenizer, review + \" TL;DR \").split(\" TL;DR \")[1].strip()\n",
        "    print(\"Generated Summary: \", summary)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pBine0sK6oz",
        "outputId": "eacb9b62-1ec6-4f71-90b7-cc1893d0e225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Review:  After reading a previous review I carefully inspected the cans when they arrived. The cans were immaculate and very clean so I felt relieved. After cooling in the fridge I ate the first can. The fruit was very mushy and not attractive to look at and frankly a disapointment but did not taste rotten per say. Only minutes later though my mouth felt like acid was eating at it and was very painful for hours even after washing out my mouth. I eat much canned and fresh fruit and this was a first for me. Only days later my teeth and gums were infected and I had to go to the dentist for the pain was so bad. He found infection and I had to undergo a treatment of antibiotics and painkillers before I was finally ok again after about 2 weeks. SHEESH! Needless to say I threw out the remaining cans of fruit! The problem must be at the source as the cans and packaging were 1st rate and shining clean. Quality control must really suck. I'm all for natural but great care must be taken so contamination is avoided. This is a foreign product and their health standards may be lacking there. I would stay far away from this stuff if you value your health! TL;DR Not Safe!\n",
            "Generated Summary:  Not Safe!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    print(\"\\nEnter your review (type 'exit' to quit):\")\n",
        "    review = input()\n",
        "    if review.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    print(\"Enter your summary prompt (press Enter for default ' TL;DR '):\")\n",
        "    summary_prompt = input().strip()\n",
        "    if not summary_prompt:\n",
        "        summary_prompt = \" TL;DR \"\n",
        "\n",
        "    generated_summary = model_infer(model, tokenizer, review + summary_prompt +\" TL;DR \").split(\" TL;DR \")[1].strip()\n",
        "    print(\"\\nGenerated Summary:\", generated_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brzdRc4ucU6e",
        "outputId": "d40d8b01-4649-4301-e23b-56a1d7d3d6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter your review (type 'exit' to quit):\n",
            "\"The Fender CD-60S Dreadnought Acoustic Guitar is a great instrument for beginners. It has a solid construction, produces a rich sound, and feels comfortable to play. However, some users have reported issues with the tuning stability.\"\n",
            "Enter your summary prompt (press Enter for default ' TL;DR '):\n",
            "\"Good for beginners but has tuning stability issues.\"\n",
            "\n",
            "Generated Summary: an\n",
            "\n",
            "Enter your review (type 'exit' to quit):\n",
            "exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = Rouge()\n",
        "\n",
        "scores = rouge.get_scores(generated_summary, summary_prompt)\n",
        "rouge1_precision = scores[0]['rouge-1']['p']\n",
        "rouge1_recall = scores[0]['rouge-1']['r']\n",
        "rouge1_f1 = scores[0]['rouge-1']['f']\n",
        "\n",
        "rouge2_precision = scores[0]['rouge-2']['p']\n",
        "rouge2_recall = scores[0]['rouge-2']['r']\n",
        "rouge2_f1 = scores[0]['rouge-2']['f']\n",
        "\n",
        "rougeL_precision = scores[0]['rouge-l']['p']\n",
        "rougeL_recall = scores[0]['rouge-l']['r']\n",
        "rougeL_f1 = scores[0]['rouge-l']['f']\n",
        "\n",
        "print(\"ROUGE-1 Precision:\", rouge1_precision)\n",
        "print(\"ROUGE-1 Recall:\", rouge1_recall)\n",
        "print(\"ROUGE-1 F1 Score:\", rouge1_f1)\n",
        "\n",
        "print(\"\\nROUGE-2 Precision:\", rouge2_precision)\n",
        "print(\"ROUGE-2 Recall:\", rouge2_recall)\n",
        "print(\"ROUGE-2 F1 Score:\", rouge2_f1)\n",
        "\n",
        "print(\"\\nROUGE-L Precision:\", rougeL_precision)\n",
        "print(\"ROUGE-L Recall:\", rougeL_recall)\n",
        "print(\"ROUGE-L F1 Score:\", rougeL_f1)"
      ],
      "metadata": {
        "id": "qF5wiWsaK_VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kHCO8qYE6cVp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}